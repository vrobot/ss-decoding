# Required:
python: /mnt/ss-decoding/vk/ss-decoding/.venv/bin/python  # Path to your venv python
model_id: Qwen/Qwen1.5-7B
data_file: /mnt/ss-decoding/datasets/sharegpt/ShareGPT_V3_unfiltered_cleaned_split.json # Path to your data
act_dir: ./acts_output          # Directory for activations
head_dir: ./heads_output         # Directory for LSQ heads
log_dir: ./logs_output          # Directory for logs (launcher itself doesn't write here yet)

# Model and Data Config:
# model_alias: tiny             # Optional: tiny | small (overrides model_id)
n_prompts: 50000                # Number of prompts for dump_all.py
seq: 256                        # Sequence length for truncation/padding
rows: "train[50000:55000]"      # Dataset rows for eval_all_layers.py (HF slice spec)

# Phase-specific batch sizes:
dump_batch: 256                  # Batch size for dump_all.py
eval_batch: 256                  # Batch size for eval_all_layers.py

# LSQ Fit Config:
fit_lambda: 1.0e-4              # Lambda for LSQ fit
layers_per_batch: 12            # Layers per batch for fit_lsq.py (GPU memory dependent)

# Evaluation Config:
gpus: "0,1,2,3,4,5,6,7"         # CUDA_VISIBLE_DEVICES for eval_all_layers.py (empty for all/CPU)
layer_jump: 1                   # evaluate every 4 layers

# Skipping Phases (optional):
# skip_dump: false              # Set to true to skip dumping activations
# skip_fit: false               # Set to true to skip fitting LSQ heads

# HF Cache (set these in your shell environment before running, or manage in script if preferred):
# HF_HOME: /mnt/ss-decoding/hf_cache
# PYTORCH_CUDA_ALLOC_CONF: expandable_segments:True

hf_home: "/mnt/ss-decoding/.cache/huggingface"  # Or your preferred path
pytorch_cuda_alloc_conf: "expandable_segments:True" # Or other valid settings 